{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import random\n",
    "from baselineCNN import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WildFire_Dataset(Dataset):\n",
    "    def __init__(self, root_dir, mode='train', transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images.\n",
    "            mode (string): One of 'train', 'valid', or 'test'.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Paths for fire and no_fire images\n",
    "        self.fire_path = os.path.join(root_dir, mode, 'wildfire')\n",
    "        self.no_fire_path = os.path.join(root_dir, mode, 'nowildfire')\n",
    "        \n",
    "        # Get list of images\n",
    "        self.fire_images = [os.path.join(self.fire_path, img) for img in os.listdir(self.fire_path)]\n",
    "        self.no_fire_images = [os.path.join(self.no_fire_path, img) for img in os.listdir(self.no_fire_path)]\n",
    "        \n",
    "        # Combine all images\n",
    "        self.all_images = self.fire_images + self.no_fire_images\n",
    "        \n",
    "        # If mode is not 'train', we need labels\n",
    "        if self.mode != 'train':\n",
    "            self.labels = [1] * len(self.fire_images) + [0] * len(self.no_fire_images)\n",
    "        else:\n",
    "            # For training, we don't have labels\n",
    "            self.labels = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.all_images[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            # For training, return only the image (no label)\n",
    "            return image\n",
    "        else:\n",
    "            # For validation and testing, return the image and its label\n",
    "            label = self.labels[idx]\n",
    "            return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations (you can customize these)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_path = '/home/ids/ihamdaoui-21/wildfire-prediction-dataset'\n",
    "# Create datasets\n",
    "train_dataset = WildFire_Dataset(root_dir=dataset_path, mode='train', transform=transform)\n",
    "valid_dataset = WildFire_Dataset(root_dir=dataset_path, mode='valid', transform=transform)\n",
    "test_dataset = WildFire_Dataset(root_dir=dataset_path, mode='test', transform=transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = baseline.to(device)\n",
    "optimizer = torch.optim.Adam(baseline.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, valid_loader, criterion, optimizer, num_epochs=10):\n",
    "    best_val_accuracy = 0.0\n",
    "    best_model_path = \"best_model.pth\"\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in valid_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_accuracy = 100 * correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "        \n",
    "        # Save the best model\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"Best model saved with val accuracy: {best_val_accuracy:.2f}%\")\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "    return best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pseudo_labels(model, train_loader, threshold=0.95):\n",
    "    model.eval()\n",
    "    pseudo_labeled_data = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, _ in train_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            max_probs, predicted_labels = torch.max(probabilities, dim=1)\n",
    "            \n",
    "            # Filter high-confidence predictions\n",
    "            high_confidence_indices = max_probs > threshold\n",
    "            pseudo_labeled_data.extend(\n",
    "                [(images[i].cpu(), predicted_labels[i].item()) for i in range(len(images)) if high_confidence_indices[i]]\n",
    "            )\n",
    "    \n",
    "    return pseudo_labeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_model(model, pseudo_labeled_data, valid_loader, criterion, optimizer, num_epochs=5):\n",
    "    # Create a DataLoader for pseudo-labeled data\n",
    "    pseudo_images = torch.stack([x[0] for x in pseudo_labeled_data])\n",
    "    pseudo_labels = torch.tensor([x[1] for x in pseudo_labeled_data])\n",
    "    pseudo_dataset = torch.utils.data.TensorDataset(pseudo_images, pseudo_labels)\n",
    "    pseudo_loader = DataLoader(pseudo_dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    # Fine-tune the model\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in pseudo_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in valid_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_accuracy = 100 * correct / total\n",
    "        print(f\"Fine-tuning Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(pseudo_loader):.4f}, Val Accuracy: {val_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.9411, Val Accuracy: 44.76%\n",
      "Best model saved with val accuracy: 44.76%\n",
      "Epoch [2/10], Loss: 0.6951, Val Accuracy: 44.76%\n",
      "Epoch [3/10], Loss: 0.6944, Val Accuracy: 44.76%\n",
      "Epoch [4/10], Loss: 0.6940, Val Accuracy: 55.24%\n",
      "Best model saved with val accuracy: 55.24%\n",
      "Epoch [5/10], Loss: 0.6938, Val Accuracy: 55.24%\n",
      "Epoch [6/10], Loss: 0.6935, Val Accuracy: 55.24%\n",
      "Epoch [7/10], Loss: 0.6933, Val Accuracy: 55.24%\n",
      "Epoch [8/10], Loss: 0.6931, Val Accuracy: 55.24%\n",
      "Epoch [9/10], Loss: 0.6929, Val Accuracy: 55.24%\n",
      "Epoch [10/10], Loss: 0.6928, Val Accuracy: 55.24%\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_786188/1578130913.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m best_model_path \u001b[38;5;241m=\u001b[39m train_model(model, test_loader, valid_loader, criterion, optimizer, num_epochs)\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(best_model_path))\n\u001b[0;32m----> 7\u001b[0m pseudo_labeled_data \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_pseudo_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 6\u001b[0m, in \u001b[0;36mpredict_pseudo_labels\u001b[0;34m(model, train_loader, threshold)\u001b[0m\n\u001b[1;32m      3\u001b[0m pseudo_labeled_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m images, _ \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m      7\u001b[0m         images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(images)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "threshold = 0.95\n",
    "\n",
    "best_model_path = train_model(model, test_loader, valid_loader, criterion, optimizer, num_epochs)\n",
    "\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "\n",
    "# fine_tune_model(model, pseudo_labeled_data, valid_loader, criterion, optimizer, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_labeled_data = predict_pseudo_labels(model, train_loader, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python torch",
   "language": "python",
   "name": "torch"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
